{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Load model YOLOv7**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-31T07:13:08.822889Z",
     "iopub.status.busy": "2024-12-31T07:13:08.822606Z",
     "iopub.status.idle": "2024-12-31T07:13:14.427117Z",
     "shell.execute_reply": "2024-12-31T07:13:14.426006Z",
     "shell.execute_reply.started": "2024-12-31T07:13:08.822867Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov7'...\n"
     ]
    }
   ],
   "source": [
    "# Install YOLOv7\n",
    "!git clone https://github.com/WongKinYiu/yolov7.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available. Running detection on GPU.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "def check_cuda_availability():\n",
    "    return torch.cuda.is_available()\n",
    "device = 'cuda' if check_cuda_availability() else 'cpu'\n",
    "if device == 'cuda':\n",
    "    print(\"GPU Available. Running detection on GPU.\")\n",
    "else:\n",
    "    print(\"GPU not available. Running detection on CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\n",
      "Version: 2.5.0+cu118\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3-Clause\n",
      "Location: c:\\users\\truon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages\n",
      "Requires: filelock, fsspec, jinja2, networkx, sympy, typing-extensions\n",
      "Required-by: thop, torchaudio, torchvision, ultralytics, ultralytics-thop\n"
     ]
    }
   ],
   "source": [
    "!pip show torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T07:13:14.428651Z",
     "iopub.status.busy": "2024-12-31T07:13:14.428346Z",
     "iopub.status.idle": "2024-12-31T07:13:14.434902Z",
     "shell.execute_reply": "2024-12-31T07:13:14.434241Z",
     "shell.execute_reply.started": "2024-12-31T07:13:14.428619Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/yolov7\n"
     ]
    }
   ],
   "source": [
    "# Change directory\n",
    "%cd /kaggle/working/yolov7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T07:13:14.436514Z",
     "iopub.status.busy": "2024-12-31T07:13:14.436250Z",
     "iopub.status.idle": "2024-12-31T07:13:23.325885Z",
     "shell.execute_reply": "2024-12-31T07:13:23.325029Z",
     "shell.execute_reply.started": "2024-12-31T07:13:14.436487Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/yolov7/requirements.txt (line 4)) (3.7.1)\n",
      "Collecting numpy<1.24.0,>=1.18.5 (from -r /kaggle/working/yolov7/requirements.txt (line 5))\n",
      "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/yolov7/requirements.txt (line 6)) (4.10.0.84)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/yolov7/requirements.txt (line 7)) (10.4.0)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/yolov7/requirements.txt (line 8)) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/yolov7/requirements.txt (line 9)) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/yolov7/requirements.txt (line 10)) (1.13.1)\n",
      "Requirement already satisfied: torch!=1.12.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/yolov7/requirements.txt (line 11)) (2.4.1+cu121)\n",
      "Requirement already satisfied: torchvision!=0.13.0,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/yolov7/requirements.txt (line 12)) (0.19.1+cu121)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/yolov7/requirements.txt (line 13)) (4.66.5)\n",
      "Requirement already satisfied: protobuf<4.21.3 in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/yolov7/requirements.txt (line 14)) (3.20.3)\n",
      "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/yolov7/requirements.txt (line 17)) (2.17.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/yolov7/requirements.txt (line 21)) (2.1.4)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/yolov7/requirements.txt (line 22)) (0.12.2)\n",
      "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/yolov7/requirements.txt (line 34)) (7.34.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/yolov7/requirements.txt (line 35)) (5.9.5)\n",
      "Collecting thop (from -r /kaggle/working/yolov7/requirements.txt (line 36))\n",
      "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r /kaggle/working/yolov7/requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r /kaggle/working/yolov7/requirements.txt (line 4)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r /kaggle/working/yolov7/requirements.txt (line 4)) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r /kaggle/working/yolov7/requirements.txt (line 4)) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r /kaggle/working/yolov7/requirements.txt (line 4)) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r /kaggle/working/yolov7/requirements.txt (line 4)) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r /kaggle/working/yolov7/requirements.txt (line 4)) (2.8.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r /kaggle/working/yolov7/requirements.txt (line 9)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r /kaggle/working/yolov7/requirements.txt (line 9)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r /kaggle/working/yolov7/requirements.txt (line 9)) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r /kaggle/working/yolov7/requirements.txt (line 9)) (2024.8.30)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r /kaggle/working/yolov7/requirements.txt (line 11)) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r /kaggle/working/yolov7/requirements.txt (line 11)) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r /kaggle/working/yolov7/requirements.txt (line 11)) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r /kaggle/working/yolov7/requirements.txt (line 11)) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r /kaggle/working/yolov7/requirements.txt (line 11)) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r /kaggle/working/yolov7/requirements.txt (line 11)) (2024.6.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r /kaggle/working/yolov7/requirements.txt (line 17)) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r /kaggle/working/yolov7/requirements.txt (line 17)) (1.64.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r /kaggle/working/yolov7/requirements.txt (line 17)) (3.7)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r /kaggle/working/yolov7/requirements.txt (line 17)) (71.0.4)\n",
      "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r /kaggle/working/yolov7/requirements.txt (line 17)) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r /kaggle/working/yolov7/requirements.txt (line 17)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r /kaggle/working/yolov7/requirements.txt (line 17)) (3.0.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r /kaggle/working/yolov7/requirements.txt (line 21)) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r /kaggle/working/yolov7/requirements.txt (line 21)) (2024.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython->-r /kaggle/working/yolov7/requirements.txt (line 34)) (0.19.2)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->-r /kaggle/working/yolov7/requirements.txt (line 34)) (4.4.2)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->-r /kaggle/working/yolov7/requirements.txt (line 34)) (0.7.5)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->-r /kaggle/working/yolov7/requirements.txt (line 34)) (5.7.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->-r /kaggle/working/yolov7/requirements.txt (line 34)) (3.0.47)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->-r /kaggle/working/yolov7/requirements.txt (line 34)) (2.18.0)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->-r /kaggle/working/yolov7/requirements.txt (line 34)) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->-r /kaggle/working/yolov7/requirements.txt (line 34)) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->-r /kaggle/working/yolov7/requirements.txt (line 34)) (4.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->-r /kaggle/working/yolov7/requirements.txt (line 34)) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->-r /kaggle/working/yolov7/requirements.txt (line 34)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->-r /kaggle/working/yolov7/requirements.txt (line 34)) (0.2.13)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->-r /kaggle/working/yolov7/requirements.txt (line 17)) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.7.0->-r /kaggle/working/yolov7/requirements.txt (line 11)) (1.3.0)\n",
      "Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: numpy, thop\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "albucore 0.0.16 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
      "albumentations 1.4.15 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
      "bayesian-optimization 2.0.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
      "bigframes 1.17.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
      "chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
      "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 18.1.0 which is incompatible.\n",
      "featuretools 1.31.0 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
      "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 18.1.0 which is incompatible.\n",
      "pandas-gbq 0.23.1 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\n",
      "pandas-stubs 2.1.4.231227 requires numpy>=1.26.0; python_version < \"3.13\", but you have numpy 1.23.5 which is incompatible.\n",
      "pyldavis 3.4.1 requires numpy>=1.24.2, but you have numpy 1.23.5 which is incompatible.\n",
      "woodwork 0.31.0 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
      "xarray 2024.9.0 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.23.5 thop-0.1.1.post2209072238\n"
     ]
    }
   ],
   "source": [
    "# Install requirements\n",
    "!pip install -r /kaggle/working/yolov7/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T07:13:23.327332Z",
     "iopub.status.busy": "2024-12-31T07:13:23.327090Z",
     "iopub.status.idle": "2024-12-31T07:13:26.053332Z",
     "shell.execute_reply": "2024-12-31T07:13:26.052520Z",
     "shell.execute_reply.started": "2024-12-31T07:13:23.327312Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-12-31 07:13:23--  https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt\n",
      "Resolving github.com (github.com)... 20.27.177.113\n",
      "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/b0243edf-9fb0-4337-95e1-42555f1b37cf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241231%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241231T071323Z&X-Amz-Expires=300&X-Amz-Signature=c1101f7e61c6f27c10936754e0adae0ec14a1038f7abfa6b00f332482e688fcc&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolov7.pt&response-content-type=application%2Foctet-stream [following]\n",
      "--2024-12-31 07:13:23--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/b0243edf-9fb0-4337-95e1-42555f1b37cf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241231%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241231T071323Z&X-Amz-Expires=300&X-Amz-Signature=c1101f7e61c6f27c10936754e0adae0ec14a1038f7abfa6b00f332482e688fcc&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolov7.pt&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 75587165 (72M) [application/octet-stream]\n",
      "Saving to: ‘yolov7.pt’\n",
      "\n",
      "yolov7.pt           100%[===================>]  72.08M  65.6MB/s    in 1.1s    \n",
      "\n",
      "2024-12-31 07:13:25 (65.6 MB/s) - ‘yolov7.pt’ saved [75587165/75587165]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download Weight\n",
    "!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Download Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T07:13:26.054793Z",
     "iopub.status.busy": "2024-12-31T07:13:26.054469Z",
     "iopub.status.idle": "2024-12-31T07:13:55.583097Z",
     "shell.execute_reply": "2024-12-31T07:13:55.582131Z",
     "shell.execute_reply.started": "2024-12-31T07:13:26.054761Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting roboflow\n",
      "  Downloading roboflow-1.1.50-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from roboflow) (2024.8.30)\n",
      "Collecting idna==3.7 (from roboflow)\n",
      "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: cycler in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.7)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.23.5)\n",
      "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.10.0.84)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (10.4.0)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
      "Collecting python-dotenv (from roboflow)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.32.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.2.3)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.5)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.2)\n",
      "Collecting requests-toolbelt (from roboflow)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting filetype (from roboflow)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.3.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.53.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.2)\n",
      "Downloading roboflow-1.1.50-py3-none-any.whl (81 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.5/81.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: filetype, python-dotenv, idna, requests-toolbelt, roboflow\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.10\n",
      "    Uninstalling idna-3.10:\n",
      "      Successfully uninstalled idna-3.10\n",
      "Successfully installed filetype-1.2.0 idna-3.7 python-dotenv-1.0.1 requests-toolbelt-1.0.0 roboflow-1.1.50\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Traffic-Object-10 to yolov7pytorch:: 100%|██████████| 404335/404335 [00:19<00:00, 20341.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Traffic-Object-10 in yolov7pytorch:: 100%|██████████| 9188/9188 [00:01<00:00, 6083.00it/s]\n"
     ]
    }
   ],
   "source": [
    "# Traffic object dataset \n",
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"ezd0jjnhrSajLZnjd9rL\")\n",
    "project = rf.workspace(\"nota-bota\").project(\"traffic-object-oyifo\")\n",
    "version = project.version(10)\n",
    "dataset = version.download(\"yolov7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T07:13:55.584718Z",
     "iopub.status.busy": "2024-12-31T07:13:55.584120Z",
     "iopub.status.idle": "2024-12-31T07:13:57.808446Z",
     "shell.execute_reply": "2024-12-31T07:13:57.807297Z",
     "shell.execute_reply.started": "2024-12-31T07:13:55.584684Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B disabled.\n"
     ]
    }
   ],
   "source": [
    "!wandb disabled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T07:13:57.809928Z",
     "iopub.status.busy": "2024-12-31T07:13:57.809689Z",
     "iopub.status.idle": "2024-12-31T07:13:58.395948Z",
     "shell.execute_reply": "2024-12-31T07:13:58.395029Z",
     "shell.execute_reply.started": "2024-12-31T07:13:57.809906Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T07:13:58.398888Z",
     "iopub.status.busy": "2024-12-31T07:13:58.398485Z",
     "iopub.status.idle": "2024-12-31T07:13:58.402512Z",
     "shell.execute_reply": "2024-12-31T07:13:58.401642Z",
     "shell.execute_reply.started": "2024-12-31T07:13:58.398864Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Directory\n",
    "base_dir = Path('/kaggle/working/yolov7/Traffic-Object-10')\n",
    "img_path = base_dir / 'train/images'\n",
    "label_path = base_dir / 'train/labels'\n",
    "yaml_file = base_dir / 'data.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the number of classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T07:13:58.404528Z",
     "iopub.status.busy": "2024-12-31T07:13:58.404243Z",
     "iopub.status.idle": "2024-12-31T07:13:58.419730Z",
     "shell.execute_reply": "2024-12-31T07:13:58.419054Z",
     "shell.execute_reply.started": "2024-12-31T07:13:58.404498Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes (38): ['Double_bend_right', 'No_right_turn', 'No_u_turn', 'Speed_limit_30km', 'Speed_limit_40km', 'Speed_limit_50km', 'Speed_limit_60km', 'Speed_limit_70km', 'Speed_limit_80km', 'Speed_limit_90km', 'Traffic_light_red', 'accident', 'ambulance', 'bicycle', 'bus', 'car', 'car-accident', 'crosswalk', 'cyclo', 'double_bend_right', 'excavator', 'fork_road', 'green_traffic_light', 'licence', 'motorcycle', 'narrow_road', 'no_entry', 'no_left_turn', 'no_right_turn', 'no_u_turn', 'parking_sign', 'person', 'red_traffic_light', 'rudimentary_vehicle', 'speed_limit_30km', 'speed_limit_40km', 'speed_limit_50km', 'truck']\n"
     ]
    }
   ],
   "source": [
    "# Load classes' data from YAML\n",
    "with open(yaml_file, 'r') as f:\n",
    "    data_yaml = yaml.safe_load(f)\n",
    "\n",
    "classes = data_yaml['names']\n",
    "num_classes = len(classes)\n",
    "print(f\"Classes ({num_classes}): {classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T07:13:58.420635Z",
     "iopub.status.busy": "2024-12-31T07:13:58.420405Z",
     "iopub.status.idle": "2024-12-31T07:13:58.449875Z",
     "shell.execute_reply": "2024-12-31T07:13:58.449238Z",
     "shell.execute_reply.started": "2024-12-31T07:13:58.420615Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 3281\n",
      "Number of labels: 3281\n"
     ]
    }
   ],
   "source": [
    "# Count number of images and labels\n",
    "img_files = list(img_path.glob(\"*.jpg\"))\n",
    "label_files = list(label_path.glob(\"*.txt\"))\n",
    "print(f\"Number of images: {len(img_files)}\")\n",
    "print(f\"Number of labels: {len(label_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T07:13:58.450717Z",
     "iopub.status.busy": "2024-12-31T07:13:58.450526Z",
     "iopub.status.idle": "2024-12-31T07:13:58.491278Z",
     "shell.execute_reply": "2024-12-31T07:13:58.490598Z",
     "shell.execute_reply.started": "2024-12-31T07:13:58.450700Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mismatched files: 0\n"
     ]
    }
   ],
   "source": [
    "# Check if any file mismatched \n",
    "mismatched_files = [img.stem for img in img_files if not (label_path / f\"{img.stem}.txt\").exists()]\n",
    "print(f\"Number of mismatched files: {len(mismatched_files)}\")\n",
    "if mismatched_files:\n",
    "    print(\"Mismatched files:\", mismatched_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T07:13:58.492214Z",
     "iopub.status.busy": "2024-12-31T07:13:58.491974Z",
     "iopub.status.idle": "2024-12-31T07:13:58.611060Z",
     "shell.execute_reply": "2024-12-31T07:13:58.610112Z",
     "shell.execute_reply.started": "2024-12-31T07:13:58.492191Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution:\n",
      "  red_traffic_light (32): 79 samples\n",
      "  Speed_limit_40km (4): 77 samples\n",
      "  crosswalk (17): 312 samples\n",
      "  car-accident (16): 201 samples\n",
      "  Speed_limit_80km (8): 105 samples\n",
      "  licence (23): 859 samples\n",
      "  car (15): 4819 samples\n",
      "  Speed_limit_60km (6): 66 samples\n",
      "  motorcycle (24): 4509 samples\n",
      "  bicycle (13): 60 samples\n",
      "  truck (37): 351 samples\n",
      "  Speed_limit_90km (9): 65 samples\n",
      "  Speed_limit_70km (7): 82 samples\n",
      "  Speed_limit_30km (3): 136 samples\n",
      "  person (31): 645 samples\n",
      "  accident (11): 182 samples\n",
      "  Speed_limit_50km (5): 79 samples\n",
      "  speed_limit_40km (35): 4 samples\n",
      "  no_left_turn (27): 101 samples\n",
      "  no_right_turn (28): 94 samples\n",
      "  green_traffic_light (22): 156 samples\n",
      "  speed_limit_50km (36): 4 samples\n",
      "  narrow_road (25): 41 samples\n",
      "  double_bend_right (19): 30 samples\n",
      "  bus (14): 167 samples\n",
      "  fork_road (21): 69 samples\n",
      "  ambulance (12): 129 samples\n",
      "  no_u_turn (29): 58 samples\n",
      "  cyclo (18): 6 samples\n",
      "  excavator (20): 8 samples\n",
      "  rudimentary_vehicle (33): 19 samples\n",
      "  parking_sign (30): 7 samples\n",
      "  No_u_turn (2): 2 samples\n",
      "  speed_limit_30km (34): 2 samples\n",
      "  no_entry (26): 1 samples\n",
      "  Traffic_light_red (10): 1 samples\n"
     ]
    }
   ],
   "source": [
    "# Class analysis\n",
    "label_data = []\n",
    "for label_file in label_files:\n",
    "    with open(label_file, 'r') as f:\n",
    "        for line in f:\n",
    "            class_id, *bbox = line.strip().split()\n",
    "            label_data.append(int(class_id))\n",
    "class_counts = Counter(label_data)\n",
    "print(\"Class distribution:\")\n",
    "for class_id, count in class_counts.items():\n",
    "    print(f\"  {classes[class_id]} ({class_id}): {count} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T07:13:58.612230Z",
     "iopub.status.busy": "2024-12-31T07:13:58.611966Z",
     "iopub.status.idle": "2024-12-31T07:14:09.098633Z",
     "shell.execute_reply": "2024-12-31T07:14:09.097888Z",
     "shell.execute_reply.started": "2024-12-31T07:13:58.612206Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Image size\n",
    "image_sizes = []\n",
    "for img_file in img_files:\n",
    "    img = cv2.imread(str(img_file))\n",
    "    if img is not None:\n",
    "        h, w, _ = img.shape\n",
    "        image_sizes.append((w, h))\n",
    "\n",
    "df_sizes = pd.DataFrame(image_sizes, columns=['Width', 'Height'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T07:14:09.099570Z",
     "iopub.status.busy": "2024-12-31T07:14:09.099352Z",
     "iopub.status.idle": "2024-12-31T07:14:09.119890Z",
     "shell.execute_reply": "2024-12-31T07:14:09.119247Z",
     "shell.execute_reply.started": "2024-12-31T07:14:09.099551Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3281.000000</td>\n",
       "      <td>3281.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>785.474246</td>\n",
       "      <td>550.709845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>645.393176</td>\n",
       "      <td>389.974600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>106.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>314.000000</td>\n",
       "      <td>274.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>416.000000</td>\n",
       "      <td>416.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1280.000000</td>\n",
       "      <td>720.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8416.000000</td>\n",
       "      <td>6144.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Width       Height\n",
       "count  3281.000000  3281.000000\n",
       "mean    785.474246   550.709845\n",
       "std     645.393176   389.974600\n",
       "min     106.000000    50.000000\n",
       "25%     314.000000   274.000000\n",
       "50%     416.000000   416.000000\n",
       "75%    1280.000000   720.000000\n",
       "max    8416.000000  6144.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sizes.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T07:14:09.120957Z",
     "iopub.status.busy": "2024-12-31T07:14:09.120770Z",
     "iopub.status.idle": "2024-12-31T07:14:09.246110Z",
     "shell.execute_reply": "2024-12-31T07:14:09.245234Z",
     "shell.execute_reply.started": "2024-12-31T07:14:09.120940Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Bounding boxes\n",
    "bbox_sizes = []\n",
    "for label_file in label_files:\n",
    "    with open(label_file, 'r') as f:\n",
    "        for line in f:\n",
    "            _, x_center, y_center, width, height = map(float, line.strip().split())\n",
    "            bbox_sizes.append((width, height))\n",
    "\n",
    "df_bboxes = pd.DataFrame(bbox_sizes, columns=['Width', 'Height'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T07:14:09.247331Z",
     "iopub.status.busy": "2024-12-31T07:14:09.247039Z",
     "iopub.status.idle": "2024-12-31T07:14:09.261082Z",
     "shell.execute_reply": "2024-12-31T07:14:09.260436Z",
     "shell.execute_reply.started": "2024-12-31T07:14:09.247309Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13526.000000</td>\n",
       "      <td>13526.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.140280</td>\n",
       "      <td>0.167213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.197914</td>\n",
       "      <td>0.174620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000995</td>\n",
       "      <td>0.002056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.031000</td>\n",
       "      <td>0.060218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.059370</td>\n",
       "      <td>0.103597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.152353</td>\n",
       "      <td>0.205556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Width        Height\n",
       "count  13526.000000  13526.000000\n",
       "mean       0.140280      0.167213\n",
       "std        0.197914      0.174620\n",
       "min        0.000995      0.002056\n",
       "25%        0.031000      0.060218\n",
       "50%        0.059370      0.103597\n",
       "75%        0.152353      0.205556\n",
       "max        1.000000      1.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bboxes.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T07:14:09.262232Z",
     "iopub.status.busy": "2024-12-31T07:14:09.261881Z",
     "iopub.status.idle": "2024-12-31T07:14:10.008354Z",
     "shell.execute_reply": "2024-12-31T07:14:10.007467Z",
     "shell.execute_reply.started": "2024-12-31T07:14:09.262196Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "\n",
    "HOME = \"/kaggle/working\"\n",
    "def make_ds(root, path_to_copy):\n",
    "    \n",
    "    os.makedirs(path_to_copy, exist_ok = True)\n",
    "    \n",
    "    files = glob(f\"{root}/*\")\n",
    "    for idx, file in enumerate(files):\n",
    "        if os.path.isdir(file): os.system(f\"cp -r '{file}' {path_to_copy}\")\n",
    "        elif os.path.isfile(file): os.system(f\"cp '{file}' {path_to_copy}\")\n",
    "            \n",
    "root = \"/kaggle/working/yolov7/Traffic-Object-10\"\n",
    "make_ds(root = root, path_to_copy = f\"{HOME}/datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T07:14:10.009659Z",
     "iopub.status.busy": "2024-12-31T07:14:10.009353Z",
     "iopub.status.idle": "2024-12-31T07:14:10.014139Z",
     "shell.execute_reply": "2024-12-31T07:14:10.013305Z",
     "shell.execute_reply.started": "2024-12-31T07:14:10.009633Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import cv2, yaml, random, numpy as np\n",
    "# from PIL import Image\n",
    "# from matplotlib import pyplot as plt\n",
    "# from torchvision import transforms as T\n",
    "# from glob import glob\n",
    "\n",
    "# class Visualization:\n",
    "\n",
    "#     def __init__(self, data_types, n_ims, rows, cmap=None):\n",
    "#         self.n_ims, self.rows = n_ims, rows\n",
    "#         self.cmap, self.data_types = cmap, data_types\n",
    "#         self.colors = [\"firebrick\", \"darkorange\", \"blueviolet\"]\n",
    "#         self.get_cls_names()\n",
    "#         self.get_bboxes()\n",
    "\n",
    "#     def get_cls_names(self):\n",
    "#         # Load the dataset.yaml file\n",
    "#         with open(f\"{HOME}/datasets/dataset.yaml\", 'r') as file:\n",
    "#             data = yaml.safe_load(file)\n",
    "#         # Extract class names\n",
    "#         class_names = data['names']\n",
    "        \n",
    "#         # Create a dictionary with class name as key and a unique ID as value\n",
    "#         self.class_dict = {name: idx for idx, name in enumerate(class_names)}        \n",
    "\n",
    "#     def get_bboxes(self):\n",
    "#         self.vis_datas, self.analysis_datas, self.im_paths = {}, {}, {}\n",
    "#         for data_type in self.data_types:\n",
    "#             all_bboxes, all_analysis_datas = [], {}\n",
    "#             im_paths = glob(f\"{HOME}/datasets/{data_type}/images/*\")\n",
    "#             for idx, im_path in enumerate(im_paths):\n",
    "#                 bboxes = []\n",
    "#                 if \".png\" in im_path:\n",
    "#                     im_path = im_path.replace(\".png\", \".txt\")\n",
    "#                 elif \".jpg\" in im_path:\n",
    "#                     im_path = im_path.replace(\".jpg\", \".txt\")\n",
    "#                 lbl_path = im_path.replace(\"images\", \"labels\")\n",
    "#                 try:\n",
    "#                     meta_data = open(lbl_path).readlines()\n",
    "#                 except FileNotFoundError:\n",
    "#                     print(f\"Warning: Label file not found for image: {im_path}\")\n",
    "#                     continue\n",
    "#                 for data in meta_data:\n",
    "#                     # Split the string by space and strip the newline character\n",
    "#                     parts = data.strip().split()[:5]\n",
    "#                     cls_name = parts[0]  # Class name is the first element\n",
    "#                     if cls_name in self.class_dict:\n",
    "#                         bboxes.append([cls_name] + [float(x) for x in parts[1:]])\n",
    "#                         if cls_name not in all_analysis_datas:\n",
    "#                             all_analysis_datas[cls_name] = 1\n",
    "#                         else:\n",
    "#                             all_analysis_datas[cls_name] += 1\n",
    "#                     else:\n",
    "#                         print(f\"Warning: Class name {cls_name} not found in class_dict\")  # Notify if class name is invalid\n",
    "#                 all_bboxes.append(bboxes)\n",
    "\n",
    "#             self.vis_datas[data_type] = all_bboxes\n",
    "#             self.analysis_datas[data_type] = all_analysis_datas\n",
    "#             self.im_paths[data_type] = im_paths\n",
    "\n",
    "#     def plot(self, rows, cols, count, im_path, bboxes):\n",
    "#         plt.subplot(rows, cols, count)\n",
    "#         or_im = np.array(Image.open(im_path).convert(\"RGB\"))\n",
    "#         height, width, _ = or_im.shape\n",
    "\n",
    "#         for bbox in bboxes:\n",
    "#             class_name, x_center, y_center, w, h = bbox\n",
    "\n",
    "#             # Convert YOLO format to pixel values\n",
    "#             x_min = int((x_center - w / 2) * width)\n",
    "#             y_min = int((y_center - h / 2) * height)\n",
    "#             x_max = int((x_center + w / 2) * width)\n",
    "#             y_max = int((y_center + h / 2) * height)\n",
    "\n",
    "#             color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "#             cv2.rectangle(img=or_im, pt1=(x_min, y_min), pt2=(x_max, y_max), color=color, thickness=3)\n",
    "#         plt.imshow(or_im)\n",
    "#         plt.axis(\"off\")\n",
    "#         plt.title(f\"There are {len(bboxes)} object(s) in the image.\")\n",
    "        \n",
    "#         return count + 1\n",
    "\n",
    "#     def vis(self, save_name):\n",
    "#         print(f\"{save_name.upper()} Data Visualization is in process...\\n\")\n",
    "#         assert self.cmap in [\"rgb\", \"gray\"], \"Please choose rgb or gray cmap\"\n",
    "#         if self.cmap == \"rgb\":\n",
    "#             cmap = \"viridis\"\n",
    "#         cols = self.n_ims // self.rows\n",
    "#         count = 1\n",
    "        \n",
    "#         plt.figure(figsize=(25, 20))\n",
    "\n",
    "#         indices = [random.randint(a=0, b=len(self.vis_datas[save_name]) - 1) for _ in range(self.n_ims)]\n",
    "\n",
    "#         for idx, index in enumerate(indices):\n",
    "#             if count == self.n_ims + 1:\n",
    "#                 break\n",
    "\n",
    "#             im_path, bboxes = self.im_paths[save_name][index], self.vis_datas[save_name][index]\n",
    "\n",
    "#             count = self.plot(self.rows, cols, count, im_path=im_path, bboxes=bboxes)\n",
    "\n",
    "#         plt.show()\n",
    "\n",
    "#     def data_analysis(self, save_name, color):\n",
    "#         print(\"Data analysis is in process...\\n\")\n",
    "        \n",
    "#         width, text_width, text_height = 0.7, 0.05, 2\n",
    "#         cls_names = list(self.analysis_datas[save_name].keys())\n",
    "#         counts = list(self.analysis_datas[save_name].values())\n",
    "\n",
    "#         _, ax = plt.subplots(figsize=(30, 10))\n",
    "#         indices = np.arange(len(counts))\n",
    "\n",
    "#         ax.bar(indices, counts, width, color=color)\n",
    "#         ax.set_xlabel(\"Class Names\", color=\"black\")\n",
    "#         ax.set_xticklabels(cls_names)\n",
    "#         ax.set(xticks=indices, xticklabels=cls_names)\n",
    "#         ax.set_ylabel(\"Data Counts\", color=\"black\")\n",
    "#         ax.set_title(f\"{save_name.upper()} Dataset Class Imbalance Analysis\")\n",
    "\n",
    "#         for i, v in enumerate(counts):\n",
    "#             ax.text(i - text_width, v + text_height, str(v), color=\"royalblue\")\n",
    "\n",
    "#     def visualization(self):\n",
    "#         [self.vis(save_name) for save_name in self.data_types]\n",
    "\n",
    "#     def analysis(self):\n",
    "#         [self.data_analysis(save_name, color) for (save_name, color) in zip(self.data_types, self.colors)]\n",
    "\n",
    "# # Run visualization and analysis\n",
    "# vis = Visualization(data_types=[\"train\", \"val\", \"test\"], n_ims=20, rows=5, cmap=\"rgb\")\n",
    "# vis.analysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T07:14:10.015305Z",
     "iopub.status.busy": "2024-12-31T07:14:10.015065Z",
     "iopub.status.idle": "2024-12-31T07:14:10.030053Z",
     "shell.execute_reply": "2024-12-31T07:14:10.029401Z",
     "shell.execute_reply.started": "2024-12-31T07:14:10.015284Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# vis.visualization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T07:14:10.031212Z",
     "iopub.status.busy": "2024-12-31T07:14:10.030940Z",
     "iopub.status.idle": "2024-12-31T07:14:10.042386Z",
     "shell.execute_reply": "2024-12-31T07:14:10.041608Z",
     "shell.execute_reply.started": "2024-12-31T07:14:10.031154Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # Re-shape images to 640-640\n",
    "\n",
    "# import cv2\n",
    "\n",
    "# # Folders\n",
    "# folders = ['train/images', 'test/images', 'split/images']\n",
    "\n",
    "# # Target size\n",
    "# target_size = (640, 640)\n",
    "\n",
    "# def resize_and_replace_images(folder_path, target_size):\n",
    "#     folder = base_dir / folder_path\n",
    "#     print('Resizing...')\n",
    "    \n",
    "#     for img_file in folder.glob(\"*.jpg\"):\n",
    "#         img = cv2.imread(str(img_file))\n",
    "#         if img is not None:\n",
    "#             resized_img = cv2.resize(img, target_size)\n",
    "#             cv2.imwrite(str(img_file), resized_img)  # Ghi đè ảnh cũ\n",
    "#             #print(f\"Resized and replaced: {img_file}\")\n",
    "#         else:\n",
    "#             print(f\"Failed to read: {img_file}\")\n",
    "\n",
    "# for folder in folders:\n",
    "#     resize_and_replace_images(folder, target_size)\n",
    "\n",
    "# print(\"All images resized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Image Augmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T07:14:10.043323Z",
     "iopub.status.busy": "2024-12-31T07:14:10.043101Z",
     "iopub.status.idle": "2024-12-31T07:14:10.059371Z",
     "shell.execute_reply": "2024-12-31T07:14:10.058665Z",
     "shell.execute_reply.started": "2024-12-31T07:14:10.043306Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# import albumentations as A\n",
    "# from pathlib import Path\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# import yaml\n",
    "# import os\n",
    "\n",
    "# # Directory\n",
    "# base_dir = Path('/kaggle/working/yolov7/Traffic-Object-10')\n",
    "# img_path = base_dir / 'train/images'\n",
    "# label_path = base_dir / 'train/labels'\n",
    "# yaml_file = base_dir / 'data.yaml'\n",
    "\n",
    "# # Đọc class distribution\n",
    "# class_counts = Counter(label_data)\n",
    "# min_samples = 100  # Ngưỡng tối thiểu cho mỗi class\n",
    "\n",
    "# # Định nghĩa augmentation với CoarseDropout thay vì Cutout\n",
    "# augmentations = A.Compose([\n",
    "#     A.HorizontalFlip(p=0.5),\n",
    "#     A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
    "#     A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "#     A.CoarseDropout(max_holes=2, max_height=50, max_width=50, fill_value=0, p=0.5),\n",
    "# ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\n",
    "\n",
    "# def load_image_and_labels(image_path, label_path):\n",
    "#     \"\"\"Load image and corresponding YOLO format labels.\"\"\"\n",
    "#     image = cv2.imread(str(image_path))\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "#     bboxes = []\n",
    "#     class_labels = []\n",
    "    \n",
    "#     if label_path.exists():\n",
    "#         with open(label_path, 'r') as f:\n",
    "#             for line in f:\n",
    "#                 class_id, x, y, w, h = map(float, line.strip().split())\n",
    "#                 bboxes.append([x, y, w, h])\n",
    "#                 class_labels.append(int(class_id))\n",
    "                \n",
    "#     return image, np.array(bboxes), class_labels\n",
    "\n",
    "# def save_augmented_data(image, bboxes, class_labels, img_save_path, label_save_path):\n",
    "#     \"\"\"Save augmented image and labels.\"\"\"\n",
    "#     # Save image\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "#     cv2.imwrite(str(img_save_path), image)\n",
    "    \n",
    "#     # Save labels\n",
    "#     with open(label_save_path, 'w') as f:\n",
    "#         for bbox, class_id in zip(bboxes, class_labels):\n",
    "#             f.write(f\"{class_id} {' '.join(map(str, bbox))}\\n\")\n",
    "\n",
    "# # Lặp qua các lớp có số lượng thấp\n",
    "# for class_id, count in class_counts.items():\n",
    "#     if count < min_samples:\n",
    "#         print(f\"Tăng cường dữ liệu cho class {classes[class_id]} ({class_id})\")\n",
    "        \n",
    "#         # Tìm tất cả các ảnh chứa class này\n",
    "#         class_images = []\n",
    "#         for label_file in label_path.glob('*.txt'):\n",
    "#             with open(label_file, 'r') as f:\n",
    "#                 labels = f.read()\n",
    "#                 if str(class_id) in labels:\n",
    "#                     class_images.append(label_file.stem)\n",
    "        \n",
    "#         # Số lượng augmentation cần thêm\n",
    "#         num_augmentations = min_samples - count\n",
    "        \n",
    "#         # Áp dụng augmentation\n",
    "#         aug_count = 0\n",
    "#         while aug_count < num_augmentations:\n",
    "#             for img_name in class_images:\n",
    "#                 if aug_count >= num_augmentations:\n",
    "#                     break\n",
    "                    \n",
    "#                 # Load ảnh và nhãn\n",
    "#                 image_file = img_path / f\"{img_name}.jpg\"\n",
    "#                 label_file = label_path / f\"{img_name}.txt\"\n",
    "                \n",
    "#                 image, bboxes, class_labels = load_image_and_labels(image_file, label_file)\n",
    "                \n",
    "#                 # Áp dụng augmentation\n",
    "#                 augmented = augmentations(image=image, bboxes=bboxes, class_labels=class_labels)\n",
    "                \n",
    "#                 # Lưu dữ liệu đã augment\n",
    "#                 aug_img_name = f\"{img_name}_aug_{aug_count}\"\n",
    "#                 aug_img_path = img_path / f\"{aug_img_name}.jpg\"\n",
    "#                 aug_label_path = label_path / f\"{aug_img_name}.txt\"\n",
    "                \n",
    "#                 save_augmented_data(\n",
    "#                     augmented['image'],\n",
    "#                     augmented['bboxes'],\n",
    "#                     augmented['class_labels'],\n",
    "#                     aug_img_path,\n",
    "#                     aug_label_path\n",
    "#                 )\n",
    "                \n",
    "#                 aug_count += 1\n",
    "#                 print(f\"Đã tạo ảnh augmented: {aug_img_name}\")\n",
    "\n",
    "# print(\"Hoàn thành quá trình tăng cường dữ liệu!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Train model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T07:14:10.060465Z",
     "iopub.status.busy": "2024-12-31T07:14:10.060237Z",
     "iopub.status.idle": "2024-12-31T07:14:10.079322Z",
     "shell.execute_reply": "2024-12-31T07:14:10.078495Z",
     "shell.execute_reply.started": "2024-12-31T07:14:10.060445Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking dataset: Traffic-Object-10/train/images - Traffic-Object-10/valid/images\n",
      "Number of classes: 38\n",
      "Class names: ['Double_bend_right', 'No_right_turn', 'No_u_turn', 'Speed_limit_30km', 'Speed_limit_40km', 'Speed_limit_50km', 'Speed_limit_60km', 'Speed_limit_70km', 'Speed_limit_80km', 'Speed_limit_90km', 'Traffic_light_red', 'accident', 'ambulance', 'bicycle', 'bus', 'car', 'car-accident', 'crosswalk', 'cyclo', 'double_bend_right', 'excavator', 'fork_road', 'green_traffic_light', 'licence', 'motorcycle', 'narrow_road', 'no_entry', 'no_left_turn', 'no_right_turn', 'no_u_turn', 'parking_sign', 'person', 'red_traffic_light', 'rudimentary_vehicle', 'speed_limit_30km', 'speed_limit_40km', 'speed_limit_50km', 'truck']\n"
     ]
    }
   ],
   "source": [
    "# Check dataset\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "with open('/kaggle/working/yolov7/Traffic-Object-10/data.yaml', 'r') as file:\n",
    "    data = yaml.safe_load(file)\n",
    "\n",
    "def check_dataset(data):\n",
    "    print(f\"Checking dataset: {data['train']} - {data['val']}\")\n",
    "    \n",
    "    # Kiểm tra các đường dẫn\n",
    "    if not os.path.exists(data['train']):\n",
    "        print(f\"Error: Train path {data['train']} does not exist.\")\n",
    "    if not os.path.exists(data['val']):\n",
    "        print(f\"Error: Validation path {data['val']} does not exist.\")\n",
    "    \n",
    "    # Kiểm tra số lớp\n",
    "    if 'nc' not in data:\n",
    "        print(\"Error: Number of classes ('nc') is missing in the dataset.\")\n",
    "    else:\n",
    "        print(f\"Number of classes: {data['nc']}\")\n",
    "    \n",
    "    # Kiểm tra các lớp trong dataset\n",
    "    if 'names' in data:\n",
    "        print(f\"Class names: {data['names']}\")\n",
    "    else:\n",
    "        print(\"Error: Class names ('names') are missing in the dataset.\")\n",
    "\n",
    "# Gọi hàm kiểm tra dataset\n",
    "check_dataset(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T07:14:10.082713Z",
     "iopub.status.busy": "2024-12-31T07:14:10.082517Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-31 07:14:15.195328: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-31 07:14:15.391543: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-31 07:14:15.448213: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "/kaggle/working/yolov7/train.py:71: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  run_id = torch.load(weights, map_location=device).get('wandb_id') if weights.endswith('.pt') and os.path.isfile(weights) else None\n",
      "/kaggle/working/yolov7/train.py:87: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(weights, map_location=device)  # load checkpoint\n",
      "/usr/local/lib/python3.10/dist-packages/torch/functional.py:513: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3609.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Traffic-Object-10/train/labels' images and labels... 3281 found\u001b[0m\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Traffic-Object-10/valid/labels' images and labels... 864 found, 0\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 4.25, Best Possible Recall (BPR) = 0.9924\n",
      "/kaggle/working/yolov7/train.py:299: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=cuda)\n",
      "  0%|                                                   | 0/206 [00:00<?, ?it/s]/kaggle/working/yolov7/train.py:360: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(enabled=cuda):\n",
      "      0/99     1.94G   0.06621   0.01377   0.03659    0.1166         8       480\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all         864        3049       0.108      0.0979      0.0353      0.0132\n",
      "      1/99     7.76G   0.04826   0.01334   0.02794   0.08955         7       480\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all         864        3049       0.572        0.14       0.101      0.0531\n",
      "      2/99     16.1G   0.04191   0.01283   0.02364   0.07838        30       480\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all         864        3049       0.651       0.215       0.165      0.0918\n",
      "      3/99     16.1G   0.03726    0.0127   0.02055   0.07051        21       480\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all         864        3049       0.568       0.256       0.186       0.107\n",
      "      4/99     16.1G   0.03568   0.01315   0.01768   0.06651        12       480\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all         864        3049       0.434       0.347       0.193       0.116\n",
      "      5/99     16.1G   0.03367   0.01225   0.01721   0.06313       114       480"
     ]
    }
   ],
   "source": [
    "!python /kaggle/working/yolov7/train.py \\\n",
    "  --workers 8 \\\n",
    "  --device 0 \\\n",
    "  --batch-size 16 \\\n",
    "  --data \"/kaggle/working/yolov7/Traffic-Object-10/data.yaml\" \\\n",
    "  --img 480 480 \\\n",
    "  --cfg cfg/training/yolov7.yaml \\\n",
    "  --weights '/kaggle/working/yolov7/yolov7.pt' \\\n",
    "  --name yolov7 \\\n",
    "  --hyp data/hyp.scratch.p5.yaml \\\n",
    "  --epochs 100 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Reviewing Training Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Imporing necessary libraries\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Tìm thư mục huấn luyện gần đây nhất\n",
    "list_of_files = glob.glob('/kaggle/working/yolov7/runs/train/yolov7')  # Mẫu với wildcard để tìm các thư mục exp*\n",
    "if list_of_files:\n",
    "    latest_dir = max(list_of_files, key=os.path.getctime)  # Thư mục được cập nhật gần nhất\n",
    "\n",
    "    # Đường dẫn đến file results.txt\n",
    "    results_path = os.path.join(latest_dir, 'results.txt')\n",
    "\n",
    "    if os.path.exists(results_path):\n",
    "        # Đọc dữ liệu từ file results.txt\n",
    "        with open(results_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "        \n",
    "        # Kiểm tra nếu file không rỗng\n",
    "        if lines:\n",
    "            # In dòng cuối cùng (hiệu suất của epoch cuối)\n",
    "            print(\"Last line of results.txt (Final epoch performance):\")\n",
    "            print(lines[-1].strip())\n",
    "        else:\n",
    "            print(\"Results file is empty.\")\n",
    "    else:\n",
    "        print(\"Results file not found. Make sure training has completed successfully.\")\n",
    "else:\n",
    "    print(\"No training directories found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "results_path = '/kaggle/working/yolov7/runs/train/yolov7/results.txt'\n",
    "results = pd.read_csv(results_path)\n",
    "print(\"File loaded successfully.\")\n",
    "print(results.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Printing columns of the results.csv file\n",
    "print(results.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data from results.txt (with spaces as delimiters)\n",
    "results = pd.read_csv('/kaggle/working/yolov7/runs/train/yolov7/results.txt', delimiter=r'\\s+', header=None)\n",
    "\n",
    "# Extract epoch number from the first column (e.g., '0/4', '1/4', etc.)\n",
    "results['epoch'] = results[0].apply(lambda x: int(x.split('/')[0]))\n",
    "\n",
    "# Clean up column names by assigning meaningful headers (adjust as necessary)\n",
    "results.columns = ['info', 'memory', 'box_loss', 'obj_loss', 'cls_loss', 'total_loss', 'images', 'size', 'precision', 'recall', 'mAP_0.5', 'train_loss', 'val_loss', 'val_precision', 'val_recall', 'epoch']\n",
    "\n",
    "# Now, you can plot using the new 'epoch' column\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Subplot 1: mAP@0.5 over epochs\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.plot(results['epoch'], results['mAP_0.5'], label='mAP@0.5', color='blue')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('mAP@0.5')\n",
    "plt.title('mAP@0.5 over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "# Subplot 2: Training and Validation Box Loss\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.plot(results['epoch'], results['box_loss'], label='Train Box Loss', color='orange')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Box Loss')\n",
    "plt.title('Box Loss over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "# Subplot 3: Training and Validation Object Loss\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.plot(results['epoch'], results['obj_loss'], label='Train Obj Loss', color='green')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Object Loss')\n",
    "plt.title('Object Loss over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "# Subplot 4: Training and Validation Class Loss\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.plot(results['epoch'], results['cls_loss'], label='Train Class Loss', color='skyblue')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Class Loss')\n",
    "plt.title('Class Loss over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "# Subplot 5: Precision and Recall\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.plot(results['epoch'], results['precision'], label='Precision', color='navy')\n",
    "plt.plot(results['epoch'], results['recall'], label='Recall', linestyle='--', color='gold')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Precision and Recall over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "# Subplot 6: Learning Rates\n",
    "plt.subplot(2, 3, 6)\n",
    "# Add your learning rate columns here, assuming they are in the file\n",
    "# For example, if columns exist, replace `lr0`, `lr1`, `lr2` with correct column names\n",
    "plt.plot(results['epoch'], results['train_loss'], label='LR0', color='teal')  # Replace with actual learning rate columns\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.title('Learning Rates over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # Testing the trained model on new images:\n",
    "# !python detect.py \\\n",
    "#     --weights /kaggle/working/yolov7/runs/train/yolov7/weights/best.pt \\\n",
    "#     --conf 0.25 \\\n",
    "#     --img-size 640 \\\n",
    "#     --source /kaggle/input/test1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import subprocess\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "def detect_random_images(\n",
    "    image_dir='/kaggle/working/yolov7/Traffic-Object-10/test/images',\n",
    "    weights_path='/kaggle/working/yolov7/runs/train/yolov7/weights/best.pt',\n",
    "    num_images=10\n",
    "):\n",
    "    # Kiểm tra thư mục tồn tại\n",
    "    if not os.path.exists(image_dir):\n",
    "        raise FileNotFoundError(f\"Không tìm thấy thư mục ảnh: {image_dir}\")\n",
    "        \n",
    "    # Lấy danh sách tất cả các file ảnh\n",
    "    image_files = [f for f in os.listdir(image_dir) \n",
    "                  if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    \n",
    "    print(f\"Tổng số ảnh trong thư mục: {len(image_files)}\")\n",
    "    \n",
    "    if len(image_files) == 0:\n",
    "        raise ValueError(\"Không tìm thấy ảnh trong thư mục\")\n",
    "    \n",
    "    # Chọn ngẫu nhiên số ảnh mong muốn\n",
    "    num_to_select = min(num_images, len(image_files))\n",
    "    selected_images = random.sample(image_files, num_to_select)\n",
    "    \n",
    "    print(f\"\\nĐã chọn {num_to_select} ảnh ngẫu nhiên:\")\n",
    "    for img in selected_images:\n",
    "        print(f\"- {img}\")\n",
    "\n",
    "    # Tạo thư mục tạm thời để chứa các ảnh đã chọn\n",
    "    temp_dir = \"temp_selected_images\"\n",
    "    if os.path.exists(temp_dir):\n",
    "        shutil.rmtree(temp_dir)\n",
    "    os.makedirs(temp_dir)\n",
    "\n",
    "    # Copy các ảnh đã chọn vào thư mục tạm thời\n",
    "    for img in selected_images:\n",
    "        src_path = os.path.join(image_dir, img)\n",
    "        dst_path = os.path.join(temp_dir, img)\n",
    "        shutil.copy2(src_path, dst_path)\n",
    "    \n",
    "    # Tạo và chạy lệnh detect với thư mục tạm thời\n",
    "    command = [\n",
    "        \"python\", \"detect.py\",\n",
    "        \"--weights\", weights_path,\n",
    "        \"--conf\", \"0.2\",\n",
    "        \"--img-size\", \"640\",\n",
    "        \"--source\", temp_dir\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nĐang chạy detection...\")\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            command,\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            check=True\n",
    "        )\n",
    "        print(\"\\nKết quả detection:\")\n",
    "        print(result.stdout)\n",
    "        \n",
    "        if result.stderr:\n",
    "            print(\"Cảnh báo/Lỗi:\")\n",
    "            print(result.stderr)\n",
    "            \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Lỗi khi chạy detection: {e}\")\n",
    "        print(f\"Chi tiết lỗi: {e.stderr}\")\n",
    "        return False\n",
    "    finally:\n",
    "        # Dọn dẹp - xóa thư mục tạm thời\n",
    "        if os.path.exists(temp_dir):\n",
    "            shutil.rmtree(temp_dir)\n",
    "        \n",
    "    return True\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        detect_random_images()\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import Image, display\n",
    "import glob\n",
    "import random\n",
    "\n",
    "# The latest detection results are in \"runs/detect/exp\"\n",
    "output_dir = '/kaggle/working/yolov7/runs/detect/exp*'\n",
    "\n",
    "# Use glob to get the latest exp folder\n",
    "output_dirs = glob.glob(output_dir)\n",
    "\n",
    "# If there are any output directories found\n",
    "if output_dirs:\n",
    "    # Get the most recent directory based on modification time\n",
    "    latest_output_dir = max(output_dirs, key=os.path.getmtime)  \n",
    "\n",
    "    # List images in the latest output directory\n",
    "    output_images = [img for img in os.listdir(latest_output_dir) if img.endswith(('.jpg', '.png'))]\n",
    "\n",
    "    # Check if there are enough images to sample\n",
    "    num_images_to_sample = 10\n",
    "    if len(output_images) < num_images_to_sample:\n",
    "        print(f\"Only {len(output_images)} images available, adjusting sample size.\")\n",
    "        num_images_to_sample = len(output_images)\n",
    "\n",
    "    # Randomly select images from the detected images\n",
    "    selected_images = random.sample(output_images, num_images_to_sample)\n",
    "\n",
    "    # Loop through the selected detected images and display them\n",
    "    for image_name in selected_images:\n",
    "        display(Image(filename=os.path.join(latest_output_dir, image_name)))\n",
    "else:\n",
    "    print(\"No detection output directories found.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6275430,
     "sourceId": 10162450,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6376718,
     "sourceId": 10302104,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6400596,
     "sourceId": 10336626,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
